# Default RAG Configuration

# Vector Database Configuration
vector_db:
  type: chromadb  # Options: chromadb, faiss, pinecone, qdrant
  persist_directory: data/vector_index
  collection_name: cross_lingual_qa
  distance_metric: cosine  # Options: cosine, l2, ip
  
# Embedding Model Configuration
embedding:
  model_name: paraphrase-multilingual-mpnet-base-v2
  # Alternative models:
  # - paraphrase-multilingual-MiniLM-L12-v2 (384 dim, faster)
  # - multilingual-e5-large (1024 dim, better quality)
  # - bge-m3 (1024 dim, best quality)
  device: auto  # Options: auto, cpu, cuda, mps
  batch_size: 32
  normalize_embeddings: true
  cache_embeddings: true
  cache_size: 10000  # Number of embeddings to cache

# Retrieval Configuration
retrieval:
  top_k: 5
  similarity_threshold: 0.0  # Minimum similarity score
  use_hybrid_search: false
  hybrid_alpha: 0.7  # Weight for semantic search (0-1)
  use_reranking: false
  reranker_model: cross-encoder/ms-marco-MiniLM-L-6-v2
  metadata_filters: {}  # Optional filters: {language: en, dataset: squad}

# Generator Configuration
generator:
  type: mt5  # Options: mt5, openai, ollama
  model_name: google/mt5-base  # or google/mt5-large
  device: auto
  max_length: 100
  num_beams: 4
  temperature: 1.0
  early_stopping: true

# Performance Optimization
performance:
  enable_query_cache: false
  query_cache_ttl: 3600  # seconds
  enable_embedding_cache: true
  batch_processing: true
  connection_pool_size: 10

# Logging Configuration
logging:
  level: INFO  # Options: DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  log_file: logs/rag/rag_system.log
  log_retrieval_details: true
  log_generation_details: true

# API Configuration
api:
  host: 0.0.0.0
  port: 8000
  enable_cors: true
  enable_auth: false
  rate_limit: 100  # requests per minute
  timeout: 30  # seconds
